{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de70423",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "############# Markdown note ##################\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Use blue boxes for Tips and notes. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Use green boxes sparingly, and only for some specific purpose that the other boxes can't cover. For example, if you have a lot of related content to link to, maybe you decide to use green boxes for related links from each section of a notebook. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> In general, just avoid the red boxes. </div>\n",
    "\n",
    "<img src=\"<path>\" width=20% style=\"margin-left:auto; margin-right:auto\">\n",
    "<img src=\"<path>\" width=40% style=\"float: right;\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91509d85",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# reset all programs\n",
    "rm -rf debug*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371497d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# MPI Introduction\n",
    "\n",
    "An introduction to basic concept of **Message Passing Interface** (MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1e7db-61ae-4ec9-b7b0-e42d4b9ff7db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## It is easy to parallelize a code? (1)\n",
    "\n",
    "Few comments:\n",
    "\n",
    "* For intra-node, `OpenMP` parallelization is \"simple\" **but** it is easy to reach **bad** performances...\n",
    "* `OpenAcc` provides more implicit and \"good\" parallelism than `OpenMP` but **only** supported by Nvidia...\n",
    "* `CUDA` **only** works on Nvidia GPUs, but `OpenCL` not common and easy to use...\n",
    "* `SYCL`, `oneAPI` (Intel) can offer complete solution but **only** for C++...\n",
    "\n",
    "### What about MPI?\n",
    "\n",
    "* requires **many** programming changes to go from serial to parallel version...\n",
    "* can be hard to **debug**..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebd972-373e-46fe-8759-7637af65946d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## It is easy to parallelize a code? (2)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>No free meals</b> - can’t just \"turn on\" parallelism</div>\n",
    "\n",
    "Parallel programming requires work:\n",
    "* **Code modification** - always\n",
    "* **Algorithm modification** - often\n",
    "* **New sneaky bugs** - you bet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853b1c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MPI \n",
    "\n",
    "Message-Passing Interface\n",
    "\n",
    "> MPI is *NOT* a language!\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> The MPI is a <b>standard specification</b> interface ruled by <a href=\"https://www.mpi-forum.org/\">MPI Forum</a>. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>MAIN GOAL</b> specify message-passing parallel model. </div>\n",
    "\n",
    "Extensions:\n",
    "\n",
    "* collective operators\n",
    "* dynamic process creation\n",
    "* parallel I/O\n",
    "* ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c7061-955f-4987-8e29-9a539805b8af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Story\n",
    "\n",
    "Born in 1992, first version released in 1994.\n",
    "\n",
    "Versions:\n",
    "* *MPI-1*, 1994\n",
    "* *MPI-2*, 2002\n",
    "* *MPI-3*, 2014\n",
    "* *MPI-4*, 2021\n",
    "* *MPI-5*, 2024\n",
    "\n",
    "> We will analyse *MPI-4.1*, (2023) https://www.open-mpi.org/doc/v4.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59cf21-3857-4128-a17e-b81452c9dff2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Story: MPI-1\n",
    "\n",
    "Born in 1992, first version released in 1994.\n",
    "\n",
    "> ...The standardization process began with the Workshop on Standards for Message-Passing in a Distributed Memory Environment, sponsored by the Center for Research on\n",
    "Parallel Computing, held April 29–30, 1992, in Williamsburg, Virginia...\n",
    "\n",
    "Focused mainly on **point-to-point communications**\n",
    "\n",
    "> ...MPI standard by the Fall of 1993 was set. To achieve this goal the MPI working group met every 6 weeks for two days throughout the first 9 months of 1993, and presented the draft MPI standard at the Supercomputing 93 conference in November 1993...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e78d73-99ee-4e5e-b7e5-747faf738066",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Story: MPI-2\n",
    "\n",
    "Beginning in 1995, first version released in 2002.\n",
    "\n",
    "* _classic_ **collective operators**\n",
    "* **persistent** communications\n",
    "* new types of functionality (dynamic processes, one-sided communication,\n",
    "**parallel I/O**, etc.)\n",
    "* Bindings for Fortran 90 and **C++**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9c8c9-468e-472e-8b0c-b9532a5b32b8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Story: MPI-3\n",
    "\n",
    "First version released around 2014.\n",
    "\n",
    "* Collective **non-blocking** operators\n",
    "* **non-blocking** I/O routines\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">MPI for C++ is deprecated from version MPI 3.0</div>\n",
    "\n",
    "## Story: MPI-4\n",
    "\n",
    "First version released around 2021.\n",
    "\n",
    "* **large** counter\n",
    "* **persistent** collectives\n",
    "* **partitioned** communications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3050773-35a4-40e9-b554-988e36bd7268",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What Platforms Are Targets for Implementation?\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> <b>GOAL</b> wide portability. </div>\n",
    "\n",
    "> ...Programs expressed this way may run on distributed-memory multiprocessors,\n",
    "networks of workstations, and combinations of all of these. In addition, shared-memory\n",
    "implementations, including those for multi-core processors and hybrid architectures, are\n",
    "possible....\n",
    "\n",
    "Use by general **MIMD** (Multiple Instruction, Multiple Data) programs, as well as **SPMD** (Single Program, Multiple Data) one. \n",
    "\n",
    "> ...implementations of MPI on top of standard Unix interprocessor communication protocols will provide portability to workstation clusters and heterogenous networks of workstations...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62559dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MPI Implementations\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Different <b>implementation</b> of the standard: </div>\n",
    "\n",
    "* C/C++;\n",
    "* Fortran;\n",
    "* Pyhton;\n",
    "* ...\n",
    "\n",
    "Both **open source** and **proprietary**:\n",
    "* [open-mpi](https://www.open-mpi.org/)\n",
    "* [mpich](https://www.mpich.org/)\n",
    "* [intelmpi](https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html) (proprietary)\n",
    "* [mpi4py](https://mpi4py.readthedocs.io/en/stable/index.html)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>DOCUMENTATION</b>: official used in this course (MPI 4.1) <a href=\"https://www.mpi-forum.org/docs/\">https://www.mpi-forum.org/docs/</a>. For the <b>implementation</b> we are going to use C/C++ <a href=\"https://www.open-mpi.org/doc/v4.1/\">https://www.open-mpi.org/doc/v4.1/</a>.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> For some implementations (e.g. openmpi, intelmpi) multiple <b>compilers</b> are available. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ef32e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MPI - Start coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8da23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### To start\n",
    "\n",
    "* For C++ we are going to use **mpic++** compiler (extension of **g++**) with `openmpi` MPI implementation.\n",
    "* For Python we use the `mpi4py` library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf2a05",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### C++ (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba4f7c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "C++ Source file (*.cpp) + CMake file (CMakeLists.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c70fba",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_example.cpp\n",
    "\n",
    "#include <iostream> // output library \n",
    "#include <mpi.h> // MPI library\n",
    "\n",
    "int main(int argc, char **argv) \n",
    "{\n",
    "    std::cout<< \"Hello world!\"<< std::endl;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be9fc3",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile CMakeLists.txt\n",
    "\n",
    "cmake_minimum_required(VERSION 3.2)\n",
    "project(1_MPI_Basic LANGUAGES CXX C VERSION 1.0.0) # Name of the project\n",
    "\n",
    "set(SOURCES \"\" CACHE STRING \"The sources list\") # Variable which stores the cpp files\n",
    "\n",
    "find_package(MPI REQUIRED) # Find the MPI library\n",
    "\n",
    "add_executable(${PROJECT_NAME} ${SOURCES}) # add list of files to executable\n",
    "target_link_libraries(${PROJECT_NAME} MPI::MPI_CXX) # Link MPI library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853c8ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### C++ (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f5a3c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Compile** and run code from terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b915b8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# compile program\n",
    "mkdir -p ./debug_example\n",
    "cd debug_example\n",
    "cmake -DSOURCES=\"main_example.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35d749",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program serial\n",
    "cd debug_example\n",
    "./1_MPI_Basic # classic call\n",
    "mpirun -np 1 1_MPI_Basic # mpi call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d7634",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program in parallel\n",
    "cd debug_example\n",
    "mpirun -np 2 1_MPI_Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1c8d3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program with more processes\n",
    "cd debug_example\n",
    "mpirun --oversubscribe -np 10 1_MPI_Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2fd96",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9830da",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Python Source file (*.py) and run code from terminal (**No Compilation step**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134a502",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_example.py\n",
    "\n",
    "import mpi4py # import mpi4py module\n",
    "mpi4py.rc.initialize = False  # do not initialize MPI automatically\n",
    "mpi4py.rc.finalize = False    # do not finalize MPI automatically\n",
    "\n",
    "from mpi4py import MPI # import the 'MPI' module\n",
    "\n",
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea1f7c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program serial\n",
    "python main_example.py # classic run\n",
    "mpirun -np 1 python main_example.py # mpi serial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61fe77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program in parallel\n",
    "mpirun -np 2 python main_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db62a48",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# run program with more processes\n",
    "mpirun --oversubscribe -np 10 python main_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fb7b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MPI Logic and Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790fb9d-3c6f-40a4-ab0d-b03b75f2b985",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Logic\n",
    "\n",
    "> ...all MPI operations are expressed as functions...\n",
    "\n",
    "MPI procedures are specified using a **language-independent** notation.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Arguments are marked as <b>IN</b> , <b>OUT</b> , or <b>INOUT</b> </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> Argument OUT or INOUT <b>cannot</b> be aliased. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531fdd3-7518-4432-af5e-1833a0098cc1",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI in an image...\n",
    "\n",
    "<img src=\"./Images/mpi_idea.webp\" width=90% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ad178-918e-443b-863b-91240935dd0f",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Distributed Memory Programming\n",
    "\n",
    "<img src=\"./Images/parallelism.png\" width=75% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a2d80-9d06-49f4-bb3c-396b6790fbdc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Message\n",
    "\n",
    "<img src=\"./Images/message.jpg\" width=30% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> <b>MPI Data Buffer</b>: data exchanged by the MPI procedure.</div>\n",
    "\n",
    "* **Message Data Buffer**: used in MPI communication procedures (send, receive,...)\n",
    "* **File Data Buffer**: used in MPI I/O procedures\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c9297-9b84-471b-b20d-a98131d2769b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Operation\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> <b>MPI Operation</b>: a sequence of steps performed by the MPI library.</div>\n",
    "\n",
    "4 stages:\n",
    "1. **Initialization**: initialization of the variable in the operation, but _NOT_ the content of the data buffer;\n",
    "2. **Starting**: data buffer is managed\n",
    "3. **Completition**: data buffer is completed\n",
    "4. **Freeing**: return the control of all parameters to the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521bfe8-ad5e-42af-a798-6dd1160705f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Operation Types\n",
    "\n",
    "* **Blocking**\n",
    " \n",
    "<img src=\"./Images/block.png\" width=30% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "* **Nonblocking**\n",
    "\n",
    "<img src=\"./Images/non_block.png\" width=30% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "* **Persistent**\n",
    "\n",
    "<img src=\"./Images/persistent.png\" width=30% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939600f4-a6e0-4b6d-aaf3-a95dab05b0fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Procedure (1)\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> <b>MPI procedure</b>: is a subpart of an MPI operation.</div>\n",
    "\n",
    "MPI procedures can be:\n",
    "* **Nonlocal**: if returning requires, during its execution, some specific semantically-related MPI procedure to be called on another MPI process\n",
    "* **Local**: if it is not nonlocal\n",
    "* **Completing**: if return from the procedure indicates that at least one associated operation has finished its completion stage, which implies that the user can rely on the content of the output data buffers\n",
    "* **Incomplete**: if it is not completing.\n",
    "\n",
    "> ...in most cases incomplete procedures are local and completing procedures are nonlocal..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3874946a-7c88-464d-9670-4172a89a93e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Procedures (2)\n",
    "\n",
    "* **Nonblocking**: if it is incomplete and local\n",
    "* **Blocking**: if it is not nonblocking\n",
    "* **Collective**: if all processes in a group or groups of MPI processes need to invoke the procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24cef35-325b-4a6b-8015-0abb03ab4437",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MPI Process\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> MPI program consists of <b>autonomous processes</b>, executing their own code (<b>MIMD</b> style). </div>\n",
    "\n",
    "* The codes executed by each process need **NOT** be identical. \n",
    "* The processes **communicate** via calls to MPI communication primitives. \n",
    "* Each process executes in its **OWN** address space\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Shared-memory implementations of MPI are possible </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc30435-3831-4767-920f-b30d485e428b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MPI Parallel session - Init and Finalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a90f70-8e7f-496d-ad88-9ef1dcc37fbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Opaque Objects (1)\n",
    "\n",
    "**MPI manages system memory** that is used for buffering messages and for storing internal\n",
    "representations of various MPI objects (such as groups, communicators, datatypes, ...)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> This memory is not directly accessible to the user, and objects stored there are <b>OPAQUE</b>: their size and shape is not visible to the user. </div>\n",
    "\n",
    "* Opaque objects are accessed via **handles**, which exist in user space.\n",
    "* MPI procedures that operate on opaque objects are passed handle arguments to access these objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b657560-0fce-4ddf-9ce5-51352602b05b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Opaque Objects (2)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> ⚠️ <b>NOTE:</b> opaque object and its handle are significant only at the process where the object was created and cannot be transferred to another process. The user must not free such objects. </div>\n",
    "\n",
    "> ...This design hides the internal representation used for MPI data structures, thus allowing similar calls in C and Fortran..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46158565",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Init and Finalize\n",
    "\n",
    "Calls used to initialize and terminate the parallel session.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> 🔵 They <b>allocate</b> and <b>deallocate</b> the opaque objects 🔵</div>\n",
    "\n",
    "* `MPI_Init`: see https://www.open-mpi.org/doc/v4.1/man3/MPI_Init.3.php\n",
    "* `MPI_Finalize`: see https://www.open-mpi.org/doc/v4.1/man3/MPI_Finalize.3.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f9818",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### C++ (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dcd26",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_init.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv) \n",
    "{\n",
    "    // Initialize MPI\n",
    "    // This must always be called before any other MPI functions\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    std::cout<< \"Hello world!\"<< std::endl;\n",
    "\n",
    "    // Finalize MPI\n",
    "    // This must always be called after all other MPI functions\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039670f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> The arguments in <code>MPI_Init</code> are <strong>not used</strong> anymore but some compilers insist they are there. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76ac0e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### C++ (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f71b3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# compile program\n",
    "mkdir -p ./debug_init\n",
    "cd debug_init\n",
    "cmake -DSOURCES=\"main_init.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a82bd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "cd debug_init\n",
    "mpirun -np 4 1_MPI_Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f745a2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0271a3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_init.py\n",
    "\n",
    "import mpi4py\n",
    "mpi4py.rc.initialize = False  # do not initialize MPI automatically\n",
    "mpi4py.rc.finalize = False    # do not finalize MPI automatically\n",
    "\n",
    "from mpi4py import MPI # import the 'MPI' module\n",
    "\n",
    "# manual initialization of the MPI environment\n",
    "MPI.Init()\n",
    "\n",
    "print(\"Hello world!\")\n",
    "\n",
    "# manual finalization of the MPI environment\n",
    "MPI.Finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e532c77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "mpirun -np 4 python main_init.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abba90c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MPI Communicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ff242",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is possible to divide the total number of processes (tasks) into groups called **communicators**.\n",
    "\n",
    "> ...A communicator specifies the communication context for a communication operation...\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">The default communicator is called <code>MPI_COMM_WORLD</code> and includes <b>all</b> the tasks available to the program.</div>\n",
    "\n",
    "<img src=\"./Images/COMM_WORLD.png\" width=40% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219e483-d742-4eec-a990-a921ccbe591f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The group inside the communicator must be a **finite size**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> The group is <b>ordered</b> and MPI processes are identified by their <b>RANK</b> within this group </div>\n",
    "\n",
    "* `MPI_Comm_size`: see https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_size.3.php\n",
    "* `MPI_Comm_rank`: see https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_rank.3.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d86be2-d4ca-4e2d-94ad-8d08463c0ce0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MPI in an image...now we know\n",
    "\n",
    "<img src=\"./Images/mpi_idea.webp\" width=90% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc601c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_communicators.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    int err;\n",
    "    err = MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int nprocs, my_rank;\n",
    "    \n",
    "    // Get the number of processes in MPI_COMM_WORLD\n",
    "    err = MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n",
    "    \n",
    "    // Get the rank of this process in MPI_COMM_WORLD\n",
    "    err = MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "    std::cout<< \"Hello I am process \"<< my_rank<< \" of \"<< nprocs<< \" processes\"<< std::endl; \n",
    "    \n",
    "    err = MPI_Finalize();\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484a4bd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <ol>\n",
    "        <li> Remember that <b>every</b> process is running the same code independently \n",
    "        <li> At the end of the call, rank will have a <b>different</b> value for every process!\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf53e29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# compile program\n",
    "mkdir -p ./debug_communicators\n",
    "cd debug_communicators\n",
    "cmake -DSOURCES=\"main_communicators.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2f0b1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "cd debug_communicators\n",
    "mpirun -np 4 1_MPI_Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33383ee6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Communicator Creation\n",
    "\n",
    "Communicators can be created with different MPI routines:\n",
    "* `MPI_Comm_split`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_split.3.php\n",
    "* `MPI_Comm_dup`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_dup.3.php\n",
    "* `MPI_Comm_create`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_create.3.php\n",
    "* ...\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> <b>REMARK</b>: Once a new communicator is created we shall <b>destroy</b> it before closing the application:</div>\n",
    "\n",
    "* `MPI_Comm_free`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_free.3.php\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b>: We are going to see more about communicators when we are going to see <b>Topologies</b>. </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e0f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example of MPI Comm Split\n",
    "\n",
    "`MPI_Comm_split`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_split.3.php\n",
    "<img src=\"./Images/comm_split.png\" width=60% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9401da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_comm_split.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <mpi.h>\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    int err;\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int nprocs, my_rank;\n",
    "    \n",
    "    // Get the rank and size in the original communicator\n",
    "    int world_rank, world_size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "\n",
    "    unsigned int color = world_rank / 4; // Determine color based on row\n",
    "    \n",
    "    // Split the communicator based on the color and use the\n",
    "    // original rank for ordering\n",
    "    MPI_Comm row_comm;\n",
    "    err = MPI_Comm_split(MPI_COMM_WORLD, color, world_rank, &row_comm);\n",
    "    \n",
    "    int row_rank, row_size;\n",
    "    MPI_Comm_rank(row_comm, &row_rank);\n",
    "    MPI_Comm_size(row_comm, &row_size);\n",
    "    \n",
    "    std::cout<< \"WORLD RANK/SIZE: \"<< world_rank<< \"/\"<< world_size<< \"\\t\";\n",
    "    std::cout<< \"ROW RANK/SIZE: \"<< row_rank<< \"/\"<< row_size<< std::endl;\n",
    "    \n",
    "    // Free the communicator\n",
    "    MPI_Comm_free(&row_comm);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43a365",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# compile program\n",
    "mkdir -p ./debug_comm_split\n",
    "cd debug_comm_split\n",
    "cmake -DSOURCES=\"main_comm_split.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134b4b6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "cd debug_comm_split\n",
    "mpirun --oversubscribe -np 16 1_MPI_Basic"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
