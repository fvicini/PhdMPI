{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de70423",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "############# Markdown note ##################\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Use blue boxes for Tips and notes. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Use green boxes sparingly, and only for some specific purpose that the other boxes can't cover. For example, if you have a lot of related content to link to, maybe you decide to use green boxes for related links from each section of a notebook. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> In general, just avoid the red boxes. </div>\n",
    "\n",
    "<img src=\"<path>\" width=20% style=\"margin-left:auto; margin-right:auto\">\n",
    "<img src=\"<path>\" width=40% style=\"float: right;\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91509d85",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# reset all programs\n",
    "rm -rf debug*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371497d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MPI Advanced\n",
    "\n",
    "Advanced concept of **Message Passing Interface** (MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526d145",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced DataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995845c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Previously on DataTypes...\n",
    "\n",
    "DataTypes can be created with different MPI routines, for example:\n",
    "\n",
    "* `MPI_Pack`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Pack.3.php\n",
    "* `MPI_Type_create_struct`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_create_struct.3.php\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Before using a new DataType, we shall <b>commit</b> it. </div>\n",
    "\n",
    "* `MPI_Type_commit`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_commit.3.php\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> <b>REMARK</b>: Once a new data type is created we shall <b>destroy</b> it before closing the application:</div>\n",
    "\n",
    "* `MPI_Type_free`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_free.3.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0538d65",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Type_Contiguous\n",
    "\n",
    "Simplest constructor. Makes count **copies** of an existing datatype\n",
    "\n",
    "* `MPI_Type_contiguous`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_contiguous.3.php\n",
    "\n",
    "<img src=\"./Images/contigous.png\" width=80% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cba101",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Type_Vector\n",
    "\n",
    "Like contiguous, but allows for regular gaps (**stride**) in the displacements. \n",
    "\n",
    "* `MPI_Type_vector`, `MPI_Type_hvector`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_vector.3.php\n",
    "\n",
    "<img src=\"./Images/vector.png\" width=60% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b>: For <code>MPI_Type_hvector</code> the stride is specified in bytes.. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad7f14",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Type_Index\n",
    "\n",
    "An array of **non regular displacements** of the input data type is provided as the map for the new data type.\n",
    "\n",
    "* `MPI_Type_indexed`, `MPI_Type_hindexed`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Type_indexed.3.php\n",
    "\n",
    "<img src=\"./Images/indexed.png\" width=60% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b>: For <code>MPI_Type_hindexed</code> offsets are specified in byte. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dcd26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile main_vector.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv) \n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    MPI_Status status;\n",
    "    double a[4][4];\n",
    "    for (unsigned int i = 0; i < 4; i++)\n",
    "        for (unsigned int j = 0; j < 4; j++)\n",
    "            a[i][j] = (rank == 0) ? i * 4.0 + j : 0.0;\n",
    "    \n",
    "    MPI_Datatype rowType, colType;\n",
    "    \n",
    "    MPI_Type_contiguous(4, MPI_DOUBLE, &rowType);\n",
    "    MPI_Type_vector(4, 2, 4, MPI_DOUBLE, &colType);\n",
    "    \n",
    "    MPI_Type_commit(&rowType);\n",
    "    MPI_Type_commit(&colType);\n",
    "    \n",
    "    if (rank == 0)\n",
    "    {\n",
    "        MPI_Send(&a[2][0], 1, rowType, 1, 10, MPI_COMM_WORLD);\n",
    "        MPI_Send(&a[0][2], 1, colType, 1, 11, MPI_COMM_WORLD);\n",
    "    }\n",
    "    else if (rank == 1)\n",
    "    {\n",
    "        MPI_Recv(&a[2][0], 1, rowType, 0, 10, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        MPI_Recv(&a[0][2], 1, colType, 0, 11, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    }\n",
    "    \n",
    "    std::cout<< \"Process \"<< rank<< \": \"<< std::endl;\n",
    "    for (unsigned int i = 0; i < 4; i++)\n",
    "    {\n",
    "        for (unsigned int j = 0; j < 4; j++)\n",
    "            std::cout<< (j == 0 ? \"\" : \", \")<< a[i][j];\n",
    "        std::cout<< std::endl;\n",
    "    }\n",
    "    \n",
    "    MPI_Type_free(&rowType);\n",
    "    MPI_Type_free(&colType);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf53e29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# compile program\n",
    "mkdir -p ./debug_vector\n",
    "cd debug_vector\n",
    "cmake -DSOURCES=\"main_vector.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2f0b1",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "cd debug_vector\n",
    "mpirun -np 2 4_MPI_Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96017a96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212d03f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Virtual topology vs Physical Topology\n",
    "\n",
    "MPI **Topology**, or **Virtual Topology** is a process arrangement in topological patterns. \n",
    "\n",
    "Examples are 2D or 3D **grid**, or more generally can be described by a **graph**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>NOTE</b>: Virtual topology can be exploited by the system in the assignment of processes to physical processors (<b>Physical Topology</b>). This helps to improve the\n",
    "communication performance on a given machine.</div>\n",
    "\n",
    "* `MPI_Cart_create`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Cart_create.3.php\n",
    "* `MPI_Graph_create`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Graph_create.3.php\n",
    "* ...\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Topology information is always associated with a <b>new communicator</b>. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33383ee6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### REMARK\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">Once a new communicator is created we shall <b>destroy</b> it before closing the application:</div>\n",
    "\n",
    "* `MPI_Comm_free`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Comm_free.3.php\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e0f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example of MPI Graph Topology\n",
    "\n",
    "`MPI_Cart_create`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Cart_create.3.php\n",
    "\n",
    "<img src=\"./Images/graph.png\" width=40% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Periodicity can be selected for each direction. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebf3fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cart Topology Utilities\n",
    "\n",
    "* `MPI_Dims_Create`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Dims_create.3.php - compute optimal balanced distribution of processes per coordinate direction with respect constraints;\n",
    "* `MPI_Cart_coords`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Cart_coords.3.php - given a rank, returns process's coordinates\n",
    "* `MPI_Cart_rank`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Cart_rank.3.php - given process's coordinates, returns the rank\n",
    "* `MPI_Cart_shift`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Cart_shift.3.php - get source and destination rank ids in SendRecv operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "871e9194",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_cart.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_cart.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv) \n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int rank, nprocs;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n",
    "    \n",
    "    int dim[] = { 0, 0 };\n",
    "    MPI_Dims_create(nprocs, 2, dim); // create 2D cart dimensions\n",
    "    \n",
    "    int period[] = {1, 0}; // periodic in the first dimension\n",
    "    MPI_Comm grid_comm;\n",
    "    MPI_Cart_create(MPI_COMM_WORLD, 2, dim, period, 1, &grid_comm);\n",
    "    \n",
    "    int new_rank;\n",
    "    int coordinates[2] = { 0, 0 };\n",
    "    MPI_Comm_rank(grid_comm, &new_rank); // new rank in the communicator\n",
    "    MPI_Cart_coords(grid_comm, new_rank, 2, coordinates); // coordinate in the grid\n",
    "    \n",
    "    std::cout<< \"Process \"<< rank<< \": \"<< \" \";\n",
    "    std::cout<< \"new_rank \"<< new_rank<< \" \";\n",
    "    std::cout<< \"coordinates \"<< coordinates[0]<< \", \"<< coordinates[1]<< std::endl;\n",
    "    \n",
    "    MPI_Barrier(grid_comm);\n",
    "    \n",
    "    int source, dest;\n",
    "    for (int direction = 0; direction < 2; direction++) \n",
    "    {\n",
    "        for (int displacement = -1; displacement < 2; displacement += 2) \n",
    "        {\n",
    "            int bufferSend = new_rank, bufferRecv = -1;\n",
    "            \n",
    "            MPI_Cart_shift(grid_comm, direction, displacement, &source, &dest);\n",
    "                        \n",
    "            MPI_Sendrecv(&bufferSend, 1, MPI_INT, source, 10, \n",
    "                         &bufferRecv, 1, MPI_INT, dest, 10,\n",
    "                         grid_comm, MPI_STATUS_IGNORE);\n",
    "            \n",
    "            std::cout<< \"Process \"<< rank<< \" - \";\n",
    "            std::cout<< \"direction \"<< direction<< \" \";\n",
    "            std::cout<< \"displacement \"<< displacement<< \": \";\n",
    "            std::cout<< \"send to \"<< dest<< \" \";\n",
    "            std::cout<< \"data \"<< bufferSend<< \"; \";\n",
    "            std::cout<< \"recv from \"<< source<< \" \";\n",
    "            std::cout<< \"data \"<< bufferRecv<< std::endl;\n",
    "        }\n",
    "    }\n",
    "           \n",
    "    MPI_Comm_free(&grid_comm);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55889f81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/geoscore/Desktop/GEO++/Courses/PhdMPI/4_MPI_Advanced/debug_cart\n",
      "Consolidate compiler generated dependencies of target 4_MPI_Advanced\n",
      "[ 50%] Building CXX object CMakeFiles/4_MPI_Advanced.dir/main_cart.cpp.o\n",
      "[100%] Linking CXX executable 4_MPI_Advanced\n",
      "[100%] Built target 4_MPI_Advanced\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# compile program\n",
    "mkdir -p ./debug_cart\n",
    "cd debug_cart\n",
    "cmake -DSOURCES=\"main_cart.cpp\" ..\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6958126f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0:  new_rank 0 coordinates 0, 0\n",
      "Process 0 - direction 0 displacement -1: send to 2 data 0; recv from 2 data 2\n",
      "Process 0 - direction 0 displacement 1: send to 2 data 0; recv from 2 data 2\n",
      "Process 0 - direction 1 displacement -1: send to -2 data 0; recv from 1 data -1\n",
      "Process 0 - direction 1 displacement 1: send to 1 data 0; recv from -2 data 1\n",
      "Process 1:  new_rank 1 coordinates 0, 1\n",
      "Process 1 - direction 0 displacement -1: send to 3 data 1; recv from 3 data 3\n",
      "Process 1 - direction 0 displacement 1: send to 3 data 1; recv from 3 data 3\n",
      "Process 1 - direction 1 displacement -1: send to 0 data 1; recv from -2 data 0\n",
      "Process 1 - direction 1 displacement 1: send to -2 data 1; recv from 0 data -1\n",
      "Process 2:  new_rank 2 coordinates 1, 0\n",
      "Process 2 - direction 0 displacement -1: send to 0 data 2; recv from 0 data 0\n",
      "Process 2 - direction 0 displacement 1: send to 0 data 2; recv from 0 data 0\n",
      "Process 2 - direction 1 displacement -1: send to -2 data 2; recv from 3 data -1\n",
      "Process 2 - direction 1 displacement 1: send to 3 data 2; recv from -2 data 3\n",
      "Process 3:  new_rank 3 coordinates 1, 1\n",
      "Process 3 - direction 0 displacement -1: send to 1 data 3; recv from 1 data 1\n",
      "Process 3 - direction 0 displacement 1: send to 1 data 3; recv from 1 data 1\n",
      "Process 3 - direction 1 displacement -1: send to 2 data 3; recv from -2 data 2\n",
      "Process 3 - direction 1 displacement 1: send to -2 data 3; recv from 2 data -1\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# run program\n",
    "cd debug_cart\n",
    "mpirun --oversubscribe -np 4 4_MPI_Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717dfe5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>NOTE</b>: negative rank can be used in send/recv. Those values correspond to constant <code>MPI_PROC_NULL</code>, ignored by communications operations </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50f76f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Circular Graph\n",
    "\n",
    "<img src=\"./Images/ring.png\" width=30% style=\"float: right;\">\n",
    "\n",
    "**Circular shift** is another typical MPI communication pattern.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">Such a pattern is nothing more than a <b>1D cartesian grid</b> topology with optional periodicity.</div>\n",
    "\n",
    "<img src=\"./Images/cart1d.png\" width=50% style=\"margin-left:auto; margin-right:auto\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0acc8c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neighbour Communications\n",
    "\n",
    "`MPI-3.0` introduced **advanced communications** for topologies:\n",
    "\n",
    "* `MPI_NEIGHBOR_ALL(GATHER[V] | TOALL[V])`: https://www.open-mpi.org/doc/v4.1/man3/MPI_Neighbor_allgather.3.php - neighbor collective communications, optimized because the communication pattern is known statically\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>NOTE:</b>There are also the <b>non-blocking</b> collective communications <code>MPI_INEIGHBOR_ALL(GATHER[V] | TOALL[V])</code>. </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc252ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One side communications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb83c02",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Standard point-to-point communications are **two-sided**: there can be a delay if the sender has to wait to send the data because the receiver is not ready.\n",
    "\n",
    "`MPI-2` standard added Remote Memory Access (**RMA**), also called **one-sided communication**.\n",
    "\n",
    "`MPI-3` further extended RMA to improve functionality and performances.\n",
    "\n",
    "<img src=\"./Images/oneside.png\" width=50% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>GOAL</b>: to <b>decouple</b> data transfer from system synchronisation. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032a65f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pros and cons of RMA\n",
    "\n",
    "**Advantages**:\n",
    "* <div class=\"alert alert-block alert-success\">Only <b>one process</b> taking part performance should be greater: no implicit synchronization, all data movement routines are non-blocking;</div>\n",
    "* <div class=\"alert alert-block alert-success\">Programs are more <b>easily written</b> with RMA: as opposed to message passing.</div>\n",
    "\n",
    "**Disadvantages**:\n",
    "* <div class=\"alert alert-block alert-danger\">The programmer shall specify the <b>synchronization</b> of the processes to write in the public memory;</div>\n",
    "* <div class=\"alert alert-block alert-danger\">In practice RMA may not be <b>faster</b>, if compared to well written P2P.</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
