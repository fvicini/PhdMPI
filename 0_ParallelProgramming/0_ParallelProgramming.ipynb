{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e384f49",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "############# Markdown note ##################\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Use blue boxes for Tips and notes. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Use green boxes sparingly, and only for some specific purpose that the other boxes can't cover. For example, if you have a lot of related content to link to, maybe you decide to use green boxes for related links from each section of a notebook. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> In general, just avoid the red boxes. </div>\n",
    "\n",
    "<img src=\"<path>\" width=20% style=\"margin-left:auto; margin-right:auto\">\n",
    "<img src=\"<path>\" width=40% style=\"float: right;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c084e9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to HPC\n",
    "High Performance Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e1574",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supercomputers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ed50e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Von Neumann architecture (1)\n",
    "\n",
    "Is the architecture of *conventional* computer processors.\n",
    "\n",
    "**Central Processing Unit** (CPU)\n",
    "\n",
    "<img src=\"./Images/Von_Neumann_Architecture.png\" width=40% style=\"float: left;\">\n",
    "<img src=\"./Images/Von_Neumann_Architecture_3.png\" width=30% style=\"float: right;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5696a7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Von Neumann architecture (2)\n",
    "\n",
    "\n",
    "1. the instruction is decoded from memory (**fetch**);\n",
    "2. Compute the **addresses** of operands;\n",
    "3. Fetch the **operands** from memory;\n",
    "4. Execute the instruction;\n",
    "5. Write the result in memory (**store**).\n",
    "\n",
    "<img src=\"./Images/Von_Neumann_Architecture_2.png\" width=35% style=\"float: right;\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>VON NEUMANN BOTTLENECK</b>: instruction fetch and a data operation <b>cannot</b> occur at the same time (since they share a common bus). Limits the <b>performance</b>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41c679",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clock cycle and frequency\n",
    "\n",
    "The **Clock Cycle** ($\\tau$), measured in `ns`, is a single increment of the CPU **clock** during which the smallest instruction is carried out.\n",
    "\n",
    "It is a **time** between two pulses of the oscillator inside the processor.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> $\\tau$ is considered the basic unit of measuring how fast an instruction can be executed by the computer processor. </div>\n",
    "\n",
    "The number of clock cycle per second is known as **Clock Speed** or **Clock Frequency** (freq), measured in `MHz` ($10^6$) or `GHz` ($10^9$), and it is a measure of processor performance.\n",
    "\n",
    "<img src=\"./Images/tau.png\" width=20% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ec091",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## FLOPS\n",
    "\n",
    "**Floating Point Operations per Second** (FLOPS), measured in `GFLOPS` ($10^{9}$) or `TFLOPS` ($10^{12}$) or `PFLOPS` ($10^{15}$), is a measure of computer performance.\n",
    "\n",
    "$$\\text{FLOPS} = \\text{cores} \\times \\text{freq} \\times \\frac{\\text{FLOPs}}{\\tau}$$\n",
    "\n",
    "where *cores* are the number of cores of the processor, *freq* is the clock speed and *FLOPs* are the number of operations in a single clock cycle.\n",
    "\n",
    "<img src=\"./Images/flops.png\" width=50% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068a6c4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Supercomputers (1)\n",
    "\n",
    "TOP500, Updated November 2022 from https://en.wikipedia.org/wiki/TOP500\n",
    "<img src=\"./Images/supercomputers.png\" width=90% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e14772",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Supercomputers (2)\n",
    "\n",
    "<img src=\"./Images/supercomputers_2.png\" width=80% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8d906",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Moore's law\n",
    "\n",
    "<img src=\"./Images/Moore.png\" width=65% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">The <b>complexity</b> of devices (number of transistors per square inch in microprocessors) doubles every 18 months...</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f66018",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Is the Moore's law the real problem?\n",
    "\n",
    "Increase in *\"transistor\" numbers* does not necessarily mean more CPU power, therefore a faster software.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">Most of the softwares <b>struggle</b> to make use of the available resources.</div>\n",
    "\n",
    "The real **limitation** is the performance difference between processors and getting data to/from memory\n",
    "\n",
    "<img src=\"./Images/memory.png\" width=25% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">Important to <b>minimise</b> the time to transfer data from/to\n",
    "the CPU</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a6297",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Memory and Processor\n",
    "\n",
    "To measure memory/data transfer performance:\n",
    "1. **Bandwidth** - how much data can be transferred in a data channel;\n",
    "2. **Latency** - the minimum time needed to transfer data.\n",
    "\n",
    "<img src=\"./Images/memory_2.png\" width=50% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4430c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cache levels\n",
    "\n",
    "Cache memory is classified in terms of **levels**, which\n",
    "describe its closeness to the microprocessor.\n",
    "* **Level 1 (L1)** - extremely fast but small (e.g 32K), usually embedded in the CPU.\n",
    "* **Level 2 (L2)** - bigger (e.g. 2Mb) but slower, maybe on a separate chip.\n",
    "* **Level 3 (L3)** - often shared among cores.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Each core usually has its own dedicated L1 and L2 cache.</div>\n",
    "\n",
    "<img src=\"./Images/cache.png\" width=30% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "In HPC exploiting the cache is crucial for performance.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">Programs waiting for data from memory are memory bound.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1089fd6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64eae71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Different parallelization types\n",
    "\n",
    "Parallelization can be present at many levels:\n",
    "* **Vector** processing (e.g. data parallelism);\n",
    "* **Hyperthreading** (e.g. 4 hardware threads/core for Intel KNL);\n",
    "* Cores / processor (e.g. 18 for Intel Broadwell);\n",
    "* Processors + **accelerators** (e.g. CPU+GPU);\n",
    "* Multiple **Nodes** in a system;\n",
    "* **Cloud-Based** Supercomputing;\n",
    "* ...\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">To reach the maximum (<b>peak</b>) performance of a parallel computer, all levels of parallelism need to be exploited.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742d1f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./Images/parallelism.png\" width=90% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e09e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parallel paradigms\n",
    "\n",
    "<img src=\"./Images/languages.png\" width=100% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890bd366",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## It is easy to parallelize a code? (1)\n",
    "\n",
    "Few comments:\n",
    "\n",
    "* For intra-node, `OpenMP` parallelization is \"simple\" **but** it is easy to reach **bad** performances...\n",
    "* `OpenAcc` provides more implicit and \"good\" parallelism than `OpenMP` but **only** supported by Nvidia...\n",
    "* `CUDA` **only** works on Nvidia GPUs, but `OpenCL` not common and easy to use...\n",
    "* `SYCL`, `oneAPI` (Intel) can offer complete solution but **only** for C++...\n",
    "\n",
    "### What about MPI?\n",
    "\n",
    "* requires **many** programming changes to go from serial to parallel version...\n",
    "* can be hard to **debug**..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1cd8a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## It is easy to parallelize a code? (2)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>No free meals</b> - canâ€™t just \"turn on\" parallelism</div>\n",
    "\n",
    "Parallel programming requires work:\n",
    "* **Code modification** - always\n",
    "* **Algorithm modification** - often\n",
    "* **New sneaky bugs** - you bet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12784a48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scalability and efficiency (1)\n",
    "\n",
    "To measure the performance of a parallel implementation:\n",
    "\n",
    "* **Scalability**: if $t_s$ is the time needed to run on a processor and $t_p(n)$ is the time needed to run on $n$ processors, the **speedup factor** ($S$) is:\n",
    "$$S(n) = \\frac{t_s}{t_p(n)} < n;$$\n",
    "* **Efficiency**: the **efficiency factor** ($\\eta_S$) on $n$ processes is:\n",
    "$$\\eta_S = \\frac{S(n)}{n} \\in (0,1].$$\n",
    "\n",
    "<img src=\"./Images/scalability.png\" width=28% style=\"float: right;\">  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">The <b>Ideal scaling</b> $S_i(n) = n$ is <b>IDEAL</b>.</div>\n",
    "\n",
    "The Speedup is **limited** by many factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8d425",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scalability and efficiency (2)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>AMDAHL'S LAW</b>: If $p$ is the portion of code benefiting from parallel implementation, the <b>theoretical speedup</b> is:\n",
    "$$S_{t} = \\frac{1}{(1-p) + \\frac{p}{S}} < \\frac{1}{1-p}$$</div>\n",
    "\n",
    "<img src=\"./Images/AmdahlsLaw.png\" width=45% style=\"margin-left:auto; margin-right:auto\"> "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
